{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0e7a6d8e8673d5b98617587ff326355db5e86db66e35dfc7c04e9041fce18bd48",
   "display_name": "Python 3.8.8 64-bit ('NeuralTranslation': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "e7a6d8e8673d5b98617587ff326355db5e86db66e35dfc7c04e9041fce18bd48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchnlp.datasets import multi30k_dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train = multi30k_dataset(train=True)\n",
    "validation = multi30k_dataset(dev=True)\n",
    "test = multi30k_dataset(test=True)"
   ]
  },
  {
   "source": [
    "## Loading data file\n",
    "file format: \n",
    "[{'en': 'A man in an orange hat starring at something.', \n",
    "'de': 'Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.'}, {}]\n",
    "\n",
    "1. add SOS EOS\n",
    "2. From unicode to acsii, delete lower case and trim punctuation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Read 1000 sentence pairs\nCounting words...\nCounted words:\nen 2176\nde 1842\n['ein mann mit einer blauen baseballkappe schlaft an einen felsen gelehnt .', 'a man with a blue baseball cap on is sleeping against a rock .']\n"
     ]
    }
   ],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "# build the dictionary\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def buildLangs(train, validation, test, reverse=False):\n",
    "    \"\"\" build Language dictionary\n",
    "    Input: set and reverse flag. Default file from Eng>De.\n",
    "        If we want to translate De->Eng, set reverse=True\n",
    "    Output: two language dictionary class from training set\n",
    "    \"\"\"\n",
    "    train_pairs = [[normalizeString(pair['en']), normalizeString(pair['de'])] \\\n",
    "        for pair in train[0:1000]]\n",
    "    # TODO: use all data\n",
    "\n",
    "    if reverse:\n",
    "        train_pairs = [list(reversed(pair)) for pair in train_pairs]\n",
    "        input_lang = Lang('en')\n",
    "        output_lang = Lang('de')\n",
    "    else: \n",
    "        input_lang = Lang('de')\n",
    "        output_lang = Lang('en')\n",
    "    return input_lang, output_lang, train_pairs\n",
    "\n",
    "def prepareData(reverse=False):\n",
    "    input_lang, output_lang, pairs = buildLangs(train, validation, test, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData(reverse=True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}